AWSTemplateFormatVersion: 2010-09-09
Description: Copy S3 object to local S3 bucket

Parameters:

  S3BucketSources:
    Type: String
    Description: S3 bucket with source files
    MaxLength: 63
    MinLength: 3
    Default: aws-bigdata-blog
  S3SourcesPrefix:
    Type: String
    Description: S3 prefix with sources WITH ending slash
    MaxLength: 63
    MinLength: 3
    Default: artifacts/aws-blog-emr-ranger
  ProjectVersion:
    Default: 3.0
    Description: Project version
    Type: String
    AllowedValues:
      - 3.0
      - beta
  ExistingS3BucketName:
      Default: ""
      Description: The bucket name where to copy the artifacts. If empty a new bucket will be created and artifacts will be copied there.
      Type: String
  S3Key:
      Description: S3Key of the code. See considerations of the ExistingS3BucketName property.
      Type: String
      Default: artifacts/aws-blog-emr-ranger
  S3Objects:
    Type: CommaDelimitedList
    Description: S3 Object to be copied
    Default: launch-cluster.zip, scripts/download-scripts.sh, scripts/remove-yum-package-name-validator.sh, scripts/configure_ranger_glue_support_with_bootstrap.sh, scripts/enable-glue-catalog-support.sh, scripts/create-hdfs-home-ba.sh, scripts/replace-trino-plugin-emr-6.9.0.sh, scripts/setup-trino-redshift-connector.sh
  CreateTLSCerts:
      Description: This flag indicates if certificates will be created inside this bucket. This will be used at deletion phase.
      Default: false
      Type: String
      AllowedValues: [ true, false ]

Conditions:
    CreateNewBucket: !Equals [!Ref "ExistingS3BucketName", ""]

Resources:

  S3BucketRegionSources:
    Type: AWS::S3::Bucket
    Condition: CreateNewBucket
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
    DeletionPolicy: Delete

  S3BucketWaitHandle:
      Condition: CreateNewBucket
      DependsOn: S3BucketRegionSources
      Type: "AWS::CloudFormation::WaitConditionHandle"

  WaitHandle:
      Type: "AWS::CloudFormation::WaitConditionHandle"

  WaitCondition:
      Type: "AWS::CloudFormation::WaitCondition"
      Properties:
        Handle: !If [CreateNewBucket, !Ref S3BucketWaitHandle, !Ref WaitHandle]
        Timeout: "1"
        Count: 0

  CopyZips:
    Type: AWS::CloudFormation::CustomResource
    DependsOn:
      - WaitCondition
    Properties:
      ServiceToken: !GetAtt 'CopyZipsFunction.Arn'
      DestBucket: !If [ CreateNewBucket, !Ref 'S3BucketRegionSources', !Ref 'ExistingS3BucketName' ]
      DestPrefix: !Ref 'S3Key'
      SourceBucket: !Ref 'S3BucketSources'
      SourcePrefix: !Ref 'S3SourcesPrefix'
      ProjectVersion: !Ref 'ProjectVersion'
      CreateTLSCerts: !Ref 'CreateTLSCerts'
      Counter: "1"
      Objects: !Ref S3Objects

  CopyZipsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:GetObjectTagging
                Resource:
                  - !Sub 'arn:aws:s3:::${S3BucketSources}/*'
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource:
                  - !Sub 'arn:aws:s3:::${S3BucketSources}'
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource:
                  - !Join [ '', [ 'arn:aws:s3:::', !If [ CreateNewBucket, !Ref 'S3BucketRegionSources', !Ref 'ExistingS3BucketName' ]]]
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:DeleteObject
                  - s3:PutObjectTagging
                Resource:
                  - !Join [ '', [ 'arn:aws:s3:::', !If [ CreateNewBucket, !Ref 'S3BucketRegionSources', !Ref 'ExistingS3BucketName' ], '/*']]

  CopyZipsFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName:  "CopyRangerArtifacts"
      Description: Copies objects from a source S3 bucket to a destination
      Handler: index.handler
      Runtime: python3.9
      Role: !GetAtt 'CopyZipsRole.Arn'
      Timeout: 240
      Code:
        ZipFile: |
          import json
          import logging
          import threading
          import boto3
          import cfnresponse

          def copy_objects(source_bucket, dest_bucket, objects, prefix, dest_prefix, project_version):
              s3 = boto3.client('s3')
              for o in objects:
                  key =  prefix + '/' + project_version + '/' + o
                  copy_source = {
                      'Bucket': source_bucket,
                      'Key': key
                  }
                  dest_key = dest_prefix + '/' + project_version + '/' + o
                  print('copy source_bucket:' + source_bucket + ' destination_bucket: '+ dest_bucket + '  source_key: ' + key + '  destination_key: ' + dest_key)
                  s3.copy_object(CopySource=copy_source, Bucket=dest_bucket, Key=dest_key)

          def delete_objects(bucket, objects, prefix, project_version, create_tls_certs):
              s3 = boto3.client('s3')
              objects = {'Objects': [{'Key':  prefix + '/' + project_version + '/' + o} for o in objects]}
              s3.delete_objects(Bucket=bucket, Delete=objects)
              #We want to delete certs only if they were created by the stack
              if create_tls_certs == 'true':
                  s3_list_response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix + '/' + project_version + '/emr-tls/')
                  if 'Contents' in s3_list_response:
                    for object in s3_list_response['Contents']:
                        print('Deleting', object['Key'])
                        s3.delete_object(Bucket=bucket, Key=object['Key'])

          def timeout(event, context):
              logging.error('Execution is about to time out, sending failure response to CloudFormation')
              cfnresponse.send(event, context, cfnresponse.FAILED, {}, None)

          def handler(event, context):
              # make sure we send a failure to CloudFormation if the function is going to timeout
              timer = threading.Timer((context.get_remaining_time_in_millis() / 1000.00) - 0.5, timeout, args=[event, context])
              timer.start()

              print('Received event:  %s' % json.dumps(event))
              status = cfnresponse.SUCCESS
              try:
                  source_bucket = event['ResourceProperties']['SourceBucket']
                  source_prefix = event['ResourceProperties']['SourcePrefix']
                  project_version = event['ResourceProperties']['ProjectVersion']
                  dest_bucket = event['ResourceProperties']['DestBucket']
                  dest_prefix = event['ResourceProperties']['DestPrefix']
                  create_tls_certs = event['ResourceProperties']['CreateTLSCerts']
                  if source_bucket == dest_bucket:
                    return
                  objects = event['ResourceProperties']['Objects']
                  if event['RequestType'] == 'Delete':
                      delete_objects(dest_bucket, objects, dest_prefix, project_version, create_tls_certs)
                  else:
                      copy_objects(source_bucket, dest_bucket, objects, source_prefix, dest_prefix, project_version)
              except Exception as e:
                  logging.error('Exception: %s' % e, exc_info=True)
                  status = cfnresponse.FAILED
              finally:
                  timer.cancel()
                  cfnresponse.send(event, context, status, {}, None)

Outputs:

  RegionalS3Bucket:
    Description:  Regional S3 bucket with artifacts required by the EMR cluster. This bucket can be reused as the 'S3Bucket' value for future EMR cluster stacks
    Value: !If [ CreateNewBucket, !Ref 'S3BucketRegionSources', !Ref 'ExistingS3BucketName' ]
